{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdfa75e",
   "metadata": {},
   "source": [
    "The dataset files given to us by the CAFA 5 team has not been properly formatted for training. In this notebook, we'll compensate by handling the dataset formatting ourselves and then upload the new dataset to HuggingFace Hub so that the CAFA 5 dataset can be made useful to the community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e116e5",
   "metadata": {},
   "source": [
    "The first thing we'll do is create a mapping of sequence IDs to their gene ontology (GO) terms stratified by their cooresponding subgraph of the gene ontology (sometimes referred to as \"aspects\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "terms_path = \"./dataset/train/train_terms.tsv\"\n",
    "\n",
    "bp_seq_to_terms = defaultdict(list)\n",
    "cc_seq_to_terms = defaultdict(list)\n",
    "mf_seq_to_terms = defaultdict(list)\n",
    "all_seq_to_terms = defaultdict(list)\n",
    "\n",
    "bp_counter = Counter()\n",
    "cc_counter = Counter()\n",
    "mf_counter = Counter()\n",
    "all_counter = Counter()\n",
    "\n",
    "df = pd.read_csv(terms_path, sep='\\t')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sequence_id = row[\"EntryID\"]\n",
    "    term_id = row[\"term\"]\n",
    "\n",
    "    match row[\"aspect\"]:\n",
    "        case \"BPO\":\n",
    "            bp_seq_to_terms[sequence_id].append(term_id)\n",
    "            bp_counter[term_id] += 1\n",
    "\n",
    "        case \"CCO\":\n",
    "            cc_seq_to_terms[sequence_id].append(term_id)\n",
    "            cc_counter[term_id] += 1\n",
    "            \n",
    "        case \"MFO\":\n",
    "            mf_seq_to_terms[sequence_id].append(term_id)\n",
    "            mf_counter[term_id] += 1\n",
    "    \n",
    "    all_seq_to_terms[sequence_id].append(term_id)\n",
    "    all_counter[term_id] += 1\n",
    "\n",
    "bp_first_5 = dict(islice(bp_seq_to_terms.items(), 5))\n",
    "cc_first_5 = dict(islice(cc_seq_to_terms.items(), 5))\n",
    "mf_first_5 = dict(islice(mf_seq_to_terms.items(), 5))\n",
    "all_first_5 = dict(islice(all_seq_to_terms.items(), 5))\n",
    "\n",
    "for seq_to_term in [bp_first_5, cc_first_5, mf_first_5, all_first_5]:\n",
    "    for sequence_id, term in seq_to_term.items():\n",
    "        print(f\"{sequence_id} => {term}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ae8ef",
   "metadata": {},
   "source": [
    "Next thing we'll do is plot the top k GO terms for each subgraph using a bar chart. This will give us an idea for how skewed and imbalanced the CAFA 5 dataset is for each GO subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943037f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_k = 40\n",
    "\n",
    "for name, counter in [\n",
    "    (\"All\", all_counter),\n",
    "    (\"Biological Process\", bp_counter),\n",
    "    (\"Cellular Component\", cc_counter),\n",
    "    (\"Molecular Function\", mf_counter),\n",
    "]:\n",
    "    counter = dict(sorted(counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    first_k = dict(islice(counter.items(), top_k))\n",
    "\n",
    "    plt.figure(figsize=(12, 5)) \n",
    "\n",
    "    plt.bar(first_k.keys(), first_k.values())\n",
    "\n",
    "    plt.title(f\"Top {top_k} {name} Term Frequencies\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"GO Term ID\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5a334",
   "metadata": {},
   "source": [
    "Next, we'll map the sequence IDs to their corresponding NCBI taxon ID. You can search the taxonomy database at https://www.ncbi.nlm.nih.gov/taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08dbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_path = \"./dataset/train/train_taxonomy.tsv\"\n",
    "\n",
    "seq_to_taxon_id = {}\n",
    "\n",
    "taxon_id_counter = Counter()\n",
    "\n",
    "df = pd.read_csv(taxonomy_path, sep='\\t')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sequence_id = row[\"EntryID\"]\n",
    "    taxon_id = row[\"taxonomyID\"]\n",
    "\n",
    "    seq_to_taxon_id[sequence_id] = taxon_id\n",
    "    taxon_id_counter[taxon_id] += 1\n",
    "\n",
    "print(f\"Number of unique taxon IDs: {len(taxon_id_counter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374cd04",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of the most common taxon IDs within the CAFA 5 dataset to determine how skewed and biased the data collection process was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 20\n",
    "\n",
    "taxon_id_count_tuples = taxon_id_counter.most_common(top_k)\n",
    "\n",
    "taxon_ids, counts = zip(*taxon_id_count_tuples)\n",
    "\n",
    "taxon_ids = [str(taxon_id) for taxon_id in taxon_ids]\n",
    "counts = list(counts)\n",
    "\n",
    "plt.bar(taxon_ids, counts)\n",
    "\n",
    "plt.title(f\"Top {top_k} Taxon ID Frequencies\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Taxon ID\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b0b2a",
   "metadata": {},
   "source": [
    "Now let's loop through the sequences provided in the Fasta file and associate their GO terms and taxonomy. we'll keep a running set of statistics for each aspect of the GO and report them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877de7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "fasta_path = \"./dataset/train/train_sequences.fasta\"\n",
    "\n",
    "mf_dataset_path = \"./dataset/mf.jsonl\"\n",
    "bp_dataset_path = \"./dataset/bp.jsonl\"\n",
    "cc_dataset_path = \"./dataset/cc.jsonl\"\n",
    "all_dataset_path = \"./dataset/all.jsonl\"\n",
    "\n",
    "for dataset_path, sequence_to_terms in [\n",
    "    (mf_dataset_path, mf_seq_to_terms),\n",
    "    (cc_dataset_path, cc_seq_to_terms),\n",
    "    (bp_dataset_path, bp_seq_to_terms),\n",
    "    (all_dataset_path, all_seq_to_terms),\n",
    "]:\n",
    "    with open(dataset_path, \"w\") as dataset_file:   \n",
    "        with open(fasta_path, \"r\") as fasta_file:\n",
    "            for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "                sequence_id = record.id\n",
    "                sequence = str(record.seq)\n",
    "\n",
    "                terms = sequence_to_terms[sequence_id]\n",
    "                taxon_id = seq_to_taxon_id[sequence_id]\n",
    "\n",
    "                seq_length = len(sequence)\n",
    "\n",
    "                line = {\n",
    "                    \"id\": sequence_id,\n",
    "                    \"sequence\": sequence,\n",
    "                    \"length\": seq_length,\n",
    "                    \"terms\": terms,\n",
    "                    \"taxon_id\": taxon_id,\n",
    "                }\n",
    "\n",
    "                dataset_file.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "    print(f\"Dataset saved to {dataset_path}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b7be2",
   "metadata": {},
   "source": [
    "Finally, let's push the properly formatted CAFA 5 dataset to HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c68204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"andrewdalpino/CAFA5\"\n",
    "\n",
    "for dataset_path, subset_name in [\n",
    "    (all_dataset_path, \"all\"),\n",
    "    (mf_dataset_path, \"mf\"),\n",
    "    (bp_dataset_path, \"bp\"),\n",
    "    (cc_dataset_path, \"cc\"),\n",
    "]:\n",
    "    hf_dataset = load_dataset(\"json\", data_files=dataset_path)\n",
    "\n",
    "    hf_dataset.push_to_hub(dataset_name, subset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
